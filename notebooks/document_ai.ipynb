{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to experiment with Document AI service on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import yaml\n",
    "import pathlib\n",
    "\n",
    "from typing import Sequence\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud auth login\n",
    "# ! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Env variables and load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(dotenv.find_dotenv(\".env_dev\"))\n",
    "root = os.environ.get(\"ROOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'deft-weaver-396616',\n",
       " 'llm': {'model': 'gemini-1.0-pro-002', 'location': 'us-central1'},\n",
       " 'documentAI': {'processor': 'a39ef57dc4bf59c2',\n",
       "  'region': 'eu',\n",
       "  'sync_max_pages': 15}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../ai_assistant/config.yaml\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = cfg.get(\"project\")\n",
    "processor_id = cfg.get(\"documentAI\").get(\"processor\") # Format is \"us\" or \"eu\"\n",
    "location = cfg.get(\"documentAI\").get(\"region\") # Create processor before running sample\n",
    "max_pages = cfg.get(\"documentAI\").get(\"sync_max_pages\")\n",
    "file_path = f\"{root}/downloads/2404.19756v2.pdf\"\n",
    "mime_type = \"application/pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Pdf file into sub-pdfs of max 15 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdfs(path, pageLimit=15):\n",
    "    folder_path = pathlib.Path(\n",
    "        '/'.join(\n",
    "            path.split(\"/\")[:-1]\n",
    "        )\n",
    "    )\n",
    "    file_name = '.'.join(\n",
    "        path.split(\"/\")[-1]\\\n",
    "            .split(\".\")[:-1]\n",
    "    )\n",
    "    all_file_paths = []\n",
    "    pdf = PdfReader(path)\n",
    "    all_pages = pdf.pages\n",
    "    \n",
    "    page_breaks = [(pageLimit*i)+1 for i in range(1, (len(all_pages)//pageLimit)+1)]\n",
    "    if len(pdf.pages) % pageLimit != 0:\n",
    "        page_breaks.append(len(all_pages)+1)\n",
    "    page_counter = 1\n",
    "    page_start = 1\n",
    "\n",
    "    for i, pg_start in enumerate(page_breaks, 1):\n",
    "        fname = f\"{file_name}_{i}.pdf\"\n",
    "        writer = PdfWriter()\n",
    "        for j in range(page_start, pg_start):\n",
    "            writer.add_page(all_pages[j-1])\n",
    "            page_counter += 1\n",
    "        print(f\"writing from {page_start} to {page_counter-1}\")\n",
    "        with open(folder_path/fname, \"wb\") as outfile:\n",
    "            writer.write(outfile)\n",
    "        all_file_paths.append(folder_path/fname)\n",
    "        page_start = pg_start\n",
    "\n",
    "    return all_file_paths\n",
    "    \n",
    "\n",
    "# all_files = split_pdfs(file_path)\n",
    "# print(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse PDF with Document AI OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> None:\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    name = client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    if len(PdfReader(file_path).pages) > max_pages:\n",
    "        all_files = split_pdfs(file_path, pageLimit=max_pages)\n",
    "    else:\n",
    "        all_files = [pathlib.Path(file_path)]\n",
    "\n",
    "    for f in all_files:\n",
    "        fname = pathlib.PurePath(f).parts[-1]\n",
    "        print(f\"Processing {fname}....\")\n",
    "        # Read the file into memory\n",
    "        with open(f, \"rb\") as image:\n",
    "            image_content = image.read()\n",
    "\n",
    "        # Load binary data\n",
    "        raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "        # For more information: https://cloud.google.com/document-ai/docs/reference/rest/v1/ProcessOptions\n",
    "        # Optional: Additional configurations for processing.\n",
    "        # process_options = documentai.ProcessOptions(\n",
    "        #     # Process only specific pages\n",
    "        #     individual_page_selector=documentai.ProcessOptions.IndividualPageSelector(\n",
    "        #         pages=[1]\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "        # Configure the process request\n",
    "        request = documentai.ProcessRequest(\n",
    "            name=name,\n",
    "            raw_document=raw_document\n",
    "        )\n",
    "\n",
    "        result = client.process_document(request=request)\n",
    "\n",
    "        # For a full list of `Document` object attributes, reference this page:\n",
    "        # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\n",
    "        document = result.document\n",
    "\n",
    "        # Read the text recognition output from the processor\n",
    "        # print(\"The document contains the following text:\")\n",
    "        # print(document.text)\n",
    "        # break\n",
    "        return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing from 1 to 15\n",
      "writing from 16 to 30\n",
      "writing from 31 to 45\n",
      "writing from 46 to 48\n",
      "Processing 2404.19756v2_1.pdf....\n"
     ]
    }
   ],
   "source": [
    "doc = process_document_sample(project_id, location, processor_id, file_path, mime_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Process payload from Document AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Document AI identifies text in different parts of the document by their\n",
    "    offsets in the entirety of the document\"s text. This function converts\n",
    "    offsets to a string.\n",
    "    \"\"\"\n",
    "    # If a text segment spans several lines, it will\n",
    "    # be stored in different text segments.\n",
    "    return \"\".join(\n",
    "        text[int(segment.start_index) : int(segment.end_index)]\n",
    "        for segment in layout.text_anchor.text_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_blocks(blocks: Sequence[documentai.Document.Page.Block], text: str) -> None:\n",
    "    print(f\"    {len(blocks)} blocks detected:\")\n",
    "    first_block_text = layout_to_text(blocks[0].layout, text)\n",
    "    print(f\"        First text block: {repr(first_block_text)}\")\n",
    "    last_block_text = layout_to_text(blocks[-1].layout, text)\n",
    "    print(f\"        Last text block: {repr(last_block_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_paragraphs(\n",
    "    paragraphs: Sequence[documentai.Document.Page.Paragraph], text: str\n",
    ") -> None:\n",
    "    print(f\"    {len(paragraphs)} paragraphs detected:\")\n",
    "    first_paragraph_text = layout_to_text(paragraphs[0].layout, text)\n",
    "    print(f\"        First paragraph text: {repr(first_paragraph_text)}\")\n",
    "    last_paragraph_text = layout_to_text(paragraphs[-1].layout, text)\n",
    "    print(f\"        Last paragraph text: {repr(last_paragraph_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    60 blocks detected:\n",
      "        First text block: 'arXiv:2404.19756v2 [cs.LG] 2 May 2024\\n'\n",
      "        Last text block: 'Preprint. Under review.\\n'\n",
      "    64 paragraphs detected:\n",
      "        First paragraph text: 'arXiv:2404.19756v2 [cs.LG] 2 May 2024\\n'\n",
      "        Last paragraph text: 'Preprint. Under review.\\n'\n"
     ]
    }
   ],
   "source": [
    "for page in doc.pages:\n",
    "    print_blocks(page.blocks, doc.text)\n",
    "    print_paragraphs(page.paragraphs, doc.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_para = iter([paragraph.layout for paragraph in doc.pages[0].paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layout_to_text(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage1_para\u001b[49m\u001b[43m)\u001b[49m, doc\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layout_to_text(next(page1_para), doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-assistant-gfWmchf1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
